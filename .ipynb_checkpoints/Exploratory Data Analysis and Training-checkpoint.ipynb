{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (595212, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin       ...        \\\n",
       "0              0              0              1              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "2              0              0              0              1       ...         \n",
       "3              0              1              0              0       ...         \n",
       "4              0              1              0              0       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the raw data\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "print('Shape of the dataset: {}'.format(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    573518\n",
       "1     21694\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is there class imbalance? The answer is very much..., it's 3.6%\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what features are we looking at?\n",
    "# there are 57 features in total (=59-2)\n",
    "all_features = df.columns.tolist()\n",
    "all_features.remove('target')\n",
    "all_features.remove('id')\n",
    "bin_features = []\n",
    "cat_features = []\n",
    "other_features = []\n",
    "for col in df.columns:\n",
    "    if col.split('_')[-1] == 'bin':\n",
    "        bin_features.append(col)\n",
    "    elif col.split('_')[-1] == 'cat':\n",
    "        cat_features.append(col)\n",
    "    else:\n",
    "        other_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bin_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ps_ind_01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_reg_01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_reg_02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_reg_03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_03_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_04_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_05_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_06_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_08_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_10_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_11_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_07</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_08</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target            0    1\n",
       "ps_ind_01       0.0  0.0\n",
       "ps_ind_02_cat   0.0  0.0\n",
       "ps_ind_03       0.0  0.0\n",
       "ps_ind_04_cat   0.0  0.0\n",
       "ps_ind_05_cat   0.0  0.0\n",
       "ps_ind_06_bin   0.0  0.0\n",
       "ps_ind_07_bin   0.0  0.0\n",
       "ps_ind_08_bin   0.0  0.0\n",
       "ps_ind_09_bin   0.0  0.0\n",
       "ps_ind_10_bin   0.0  0.0\n",
       "ps_ind_11_bin   0.0  0.0\n",
       "ps_ind_12_bin   0.0  0.0\n",
       "ps_ind_13_bin   0.0  0.0\n",
       "ps_ind_14       0.0  0.0\n",
       "ps_ind_15       0.0  0.0\n",
       "ps_ind_16_bin   0.0  0.0\n",
       "ps_ind_17_bin   0.0  0.0\n",
       "ps_ind_18_bin   0.0  0.0\n",
       "ps_reg_01       0.0  0.0\n",
       "ps_reg_02       0.0  0.0\n",
       "ps_reg_03       0.0  0.0\n",
       "ps_car_01_cat   0.0  0.0\n",
       "ps_car_02_cat   0.0  0.0\n",
       "ps_car_03_cat   0.0  0.0\n",
       "ps_car_04_cat   0.0  0.0\n",
       "ps_car_05_cat   0.0  0.0\n",
       "ps_car_06_cat   0.0  0.0\n",
       "ps_car_07_cat   0.0  0.0\n",
       "ps_car_08_cat   0.0  0.0\n",
       "ps_car_09_cat   0.0  0.0\n",
       "ps_car_10_cat   0.0  0.0\n",
       "ps_car_11_cat   0.0  0.0\n",
       "ps_car_11       0.0  0.0\n",
       "ps_car_12       0.0  0.0\n",
       "ps_car_13       0.0  0.0\n",
       "ps_car_14       0.0  0.0\n",
       "ps_car_15       0.0  0.0\n",
       "ps_calc_01      0.0  0.0\n",
       "ps_calc_02      0.0  0.0\n",
       "ps_calc_03      0.0  0.0\n",
       "ps_calc_04      0.0  0.0\n",
       "ps_calc_05      0.0  0.0\n",
       "ps_calc_06      0.0  0.0\n",
       "ps_calc_07      0.0  0.0\n",
       "ps_calc_08      0.0  0.0\n",
       "ps_calc_09      0.0  0.0\n",
       "ps_calc_10      0.0  0.0\n",
       "ps_calc_11      0.0  0.0\n",
       "ps_calc_12      0.0  0.0\n",
       "ps_calc_13      0.0  0.0\n",
       "ps_calc_14      0.0  0.0\n",
       "ps_calc_15_bin  0.0  0.0\n",
       "ps_calc_16_bin  0.0  0.0\n",
       "ps_calc_17_bin  0.0  0.0\n",
       "ps_calc_18_bin  0.0  0.0\n",
       "ps_calc_19_bin  0.0  0.0\n",
       "ps_calc_20_bin  0.0  0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many missing values, in terms of percentage, are we looking at?\n",
    "df[['target']+all_features].groupby('target')[all_features]\\\n",
    ".apply(lambda x: 100*np.sum(x == -1)/len(x)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace the -1 with NaN, so that I can use pandas.dropna...\n",
    "df.replace({-1: np.float('NaN')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    573518\n",
      "1     21694\n",
      "Name: target, dtype: int64\n",
      "0    119261\n",
      "1      5670\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# how to deal with those missing (-1) values? \n",
    "# what if I just drop them?\n",
    "print(df['target'].value_counts())  # classes before dropna\n",
    "df.dropna(how='any', inplace=True)\n",
    "print(df['target'].value_counts())  # classes after dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04538505254900705"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5670 / (5670+119261)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's handle everything in a class\n",
    "class Classifier():\n",
    "    '''\n",
    "    In this class, we will do everything, including:\n",
    "    (1) data cleaning, imputation, scaling\n",
    "    (2) possible feature engineering\n",
    "    (3) model fitting, including CV \n",
    "    (4) prediction on test data\n",
    "    (5) helper functions such as various plotting functions\n",
    "    \n",
    "    Here we heavily rely on the pandas, hence most of the datatypes is pandas dataframe\n",
    "    '''\n",
    "    def __init__(self, X_raw, y_raw):\n",
    "        '''\n",
    "        Initialization.\n",
    "        Here we assume there is no missing entry (with value of -1)\n",
    "        in the data, i.e., we've done the data cleaning step.\n",
    "        \n",
    "        Input\n",
    "        =====================\n",
    "        X_raw: <pandas dataframe> \n",
    "            The raw input, in pandas dataframe. \n",
    "            The shape should be m x n,\n",
    "            where m is the number of sample, n is the number of features\n",
    "        Y_raw: <pandas dataframe>\n",
    "            The raw binary labels, in pandas dataframe.\n",
    "            The shape should be m x 1\n",
    "            \n",
    "        Return\n",
    "        =====================\n",
    "        Nothing\n",
    "        '''\n",
    "        import time\n",
    "        \n",
    "        self.X_raw = X_raw\n",
    "        self.y_raw = y_raw\n",
    "        self.one_hot = False\n",
    "        # check for missing values\n",
    "        tmp_cnt = 0\n",
    "        tmp_cols = []\n",
    "        for col in X_raw.columns:\n",
    "            if X_raw[col].min() < 0:\n",
    "                tmp_cnt += 1\n",
    "                tmp_cols.append(col)\n",
    "        if tmp_cnt > 0:\n",
    "            print('Thre are {} features with missing value(s)'.format(tmp_cnt))\n",
    "            print('They are:')\n",
    "            for x in tmp_cols:\n",
    "                print('    ', x)\n",
    "            print('======= Please deal with the missing values first! =======\\n')\n",
    "    \n",
    "    def plot_roc(self, fpr, tpr, roc_auc, model_type='not specified'):\n",
    "        \"\"\"\n",
    "        Helper function. \n",
    "        To plot the ROC curve for a binary classifier.\n",
    "        \n",
    "        Input:\n",
    "        =========\n",
    "        fpr: <float>\n",
    "            false positive rate\n",
    "        tpr: <float>\n",
    "            true positive rate\n",
    "        roc_auc: <???>\n",
    "            ???\n",
    "            \n",
    "        Return:\n",
    "        =========\n",
    "        Nothing, draw a plot.\n",
    "        \"\"\"        \n",
    "        \n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color='darkorange',\n",
    "                 lw=lw, label='ROC curve (area = {:0.6f})'.format(roc_auc))\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic for {}'.format(model_type))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    def get_gini(self):\n",
    "        '''\n",
    "        TODO: calculate the gini coefficent\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def get_importance(self, clf, X, N=3):\n",
    "        \"\"\"\n",
    "        For the Random Forest and XGB, to get the feature importance\n",
    "        \n",
    "        TODO: finish the doc\n",
    "        \"\"\"\n",
    "        features = X.columns\n",
    "        importances = [[c, i] for c, i in zip(features, clf.feature_importances_)];\n",
    "        importances = sorted(importances, key=lambda x: x[1], reverse = True);\n",
    "        N = 3\n",
    "        print('\\nThe top {} important features are:'.format(N))\n",
    "        for j in range(N):\n",
    "            print(importances[j][0], importances[j][1])     \n",
    "    \n",
    "    def input_scaling(self, ratio=0.2):\n",
    "        '''\n",
    "        First split the total data into training and testing, with given ratio\n",
    "        and the apply the standard scaler to the training data\n",
    "        \n",
    "        Input\n",
    "        ================\n",
    "        ratio: <float>, default: 0.2\n",
    "            ratio between test and training data sizes\n",
    "        \n",
    "        Return\n",
    "        ================\n",
    "        X_train: <pandas dataframe> \n",
    "            scaled training X\n",
    "        y_train: <pandas dataframe>\n",
    "            labels for the training X\n",
    "        X_test: <pandas dataframe>\n",
    "            scaled test X\n",
    "        y_test: <pandas dataframe>\n",
    "            lables for test X\n",
    "        '''\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        #from sklearn.model_selection import GridSearchCV\n",
    "        #from sklearn.metrics import confusion_matrix\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test \\\n",
    "            = train_test_split(self.X_raw, self.y_raw, test_size=ratio)\n",
    "        # scaling the features\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(self.X_train)  # Don't cheat - fit only on training data\n",
    "        \n",
    "        self.X_train = scaler.transform(self.X_train)\n",
    "        self.X_test = scaler.transform(self.X_test)  # apply same transformation to test data\n",
    "        print('Splitted training/test, and applied standard scaler.')\n",
    "        print('Total number of training samples: {}'.format(len(self.X_train)))\n",
    "        \n",
    "    def logistic_regression(self, tuning=True, roc_plot=True):\n",
    "        '''\n",
    "        Build a logistic regression model.\n",
    "        \n",
    "        Input:\n",
    "        ======\n",
    "        tuning: <Boolean> default: True\n",
    "            If True, perform the hyper parameter tuning, with GridSearch CV\n",
    "        roc_plot: <Boolean> default: True\n",
    "            If True, plot the roc plot and calculate AUC\n",
    "        \n",
    "        Return:\n",
    "        =======\n",
    "        Nothing, but build a logistic regression classifier.\n",
    "        '''\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        \n",
    "        print('......Training a logistic regression model......')\n",
    "        if not self.one_hot:\n",
    "            print('We haven\\'t done one hot encoding yet! Quit training.')\n",
    "            return\n",
    "        # get the single classifier\n",
    "        self.lg_clf = LogisticRegression(class_weight='balanced')\n",
    "        # hyper parameters\n",
    "        parameters = {'C': np.logspace(-3, 0, num=30)}\n",
    "        \n",
    "        if tuning:  # hyper parameter tuning\n",
    "            lg_clfs = GridSearchCV(self.lg_clf, parameters, \n",
    "                                   verbose = 1, cv = 5, n_jobs = -1)\n",
    "            lg_clfs.fit(self.X_train, self.y_train)\n",
    "            self.lg_clf = lg_clfs.best_estimator_\n",
    "        else:\n",
    "            self.lg_clf.fit(self.X_train, self.y_train)\n",
    "        print('The training score is: {}'.format(self.lg_clf.score(self.X_train, self.y_train)))\n",
    "        print('The test score is: {}'.format(self.lg_clf.score(self.X_test, self.y_test)))\n",
    "        \n",
    "        if roc_plot:\n",
    "            ## get the roc curve\n",
    "            y_score = self.lg_clf.decision_function(self.X_test)\n",
    "            fpr, tpr, _ = roc_curve(self.y_test, y_score, drop_intermediate=False)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            self.plot_roc(fpr, tpr, roc_auc, model_type='Logistic Regression')\n",
    "            \n",
    "    def random_forest(self, tuning=True, roc_plot=True):\n",
    "        '''\n",
    "        Build a random forest model.\n",
    "        \n",
    "        Input:\n",
    "        ======\n",
    "        tuning: <Boolean> default: True\n",
    "            If True, perform the hyper parameter tuning, with GridSearch CV\n",
    "        roc_plot: <Boolean> default: True\n",
    "            If True, plot the roc plot and calculate AUC\n",
    "        \n",
    "        Return:\n",
    "        =======\n",
    "        Nothing, but build a random forest classifier.\n",
    "        '''\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        \n",
    "        print('......Training a random forest model......')\n",
    "        if not self.one_hot:\n",
    "            print('We haven\\'t done one hot encoding yet! Quit training.')\n",
    "            return\n",
    "        parameters = {'max_depth': [x for x in range(3, 21, 1)],\n",
    "              'n_estimators':[x for x in range(100, 401, 100)]}\n",
    "        self.rf_clf = RandomForestClassifier(class_weight='balanced',\n",
    "                                             verbose = False, random_state = True)\n",
    "        if tuning:\n",
    "            rf_clfs = GridSearchCV(self.rf_clf, parameters, \n",
    "                                   verbose = 1, cv = 5, n_jobs = -1)\n",
    "            rf_clfs.fit(self.X_train, self.y_train)\n",
    "            self.rf_clf = rf_clfs.best_estimator_\n",
    "        else:\n",
    "            self.rf_clf.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        print('The training score is: {}'.format(self.rf_clf.score(self.X_train, self.y_train)))\n",
    "        print('The test score is: {}'.format(self.rf_clf.score(self.X_test, self.y_test)))\n",
    "        \n",
    "        if roc_plot:\n",
    "            ## get the roc curve\n",
    "            y_score = self.rf_clf.predict_proba(self.X_test)\n",
    "            y_score = [x[1] for x in y_score]\n",
    "            fpr, tpr, _ = roc_curve(self.y_test, y_score, drop_intermediate=False)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            self.plot_roc(fpr, tpr, roc_auc, model_type='Random Forest')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted training/test, and applied standard scaler.\n",
      "Total number of training samples: 99944\n",
      "......Training a logistic regression model......\n",
      "We haven't done one hot encoding yet!\n"
     ]
    }
   ],
   "source": [
    "X_raw, y_raw = df[all_features], df['target']\n",
    "clf = Classifier(X_raw=X_raw, y_raw=y_raw)\n",
    "clf.input_scaling()\n",
    "# get the logistic regression going\n",
    "clf.logistic_regression(tuning=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......Training a random forest model......\n",
      "We haven't done one hot encoding yet!\n"
     ]
    }
   ],
   "source": [
    "clf.random_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
