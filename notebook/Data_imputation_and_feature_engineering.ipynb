{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training dataset: (595212, 59)\n",
      "Shape of the test dataset: (892816, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin       ...        \\\n",
       "0              0              0              1              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "2              0              0              0              1       ...         \n",
       "3              0              1              0              0       ...         \n",
       "4              0              1              0              0       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the raw data\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "print('Shape of the training dataset: {}'.format(df_train.shape))\n",
    "print('Shape of the test dataset: {}'.format(df_test.shape))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    573518\n",
       "1     21694\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is there class imbalance? The answer is very much...\n",
    "df_train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what features are we looking at?\n",
    "# there are 57 features in total (=59-2)\n",
    "all_features = df_train.columns.tolist()\n",
    "all_features.remove('target')\n",
    "all_features.remove('id')\n",
    "bin_features = []\n",
    "cat_features = []\n",
    "other_features = []\n",
    "for col in df_train.columns[2:]:  # exclude 'id' and 'target'\n",
    "    if col.split('_')[-1] == 'bin':\n",
    "        bin_features.append(col)\n",
    "    elif col.split('_')[-1] == 'cat':\n",
    "        cat_features.append(col)\n",
    "    else:\n",
    "        other_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bin_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ps_car_03_cat</th>\n",
       "      <td>69.358067</td>\n",
       "      <td>61.998709</td>\n",
       "      <td>69.089837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_05_cat</th>\n",
       "      <td>45.002772</td>\n",
       "      <td>38.960081</td>\n",
       "      <td>44.782531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_reg_03</th>\n",
       "      <td>18.257840</td>\n",
       "      <td>14.105283</td>\n",
       "      <td>18.106490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_14</th>\n",
       "      <td>7.130901</td>\n",
       "      <td>7.942288</td>\n",
       "      <td>7.160474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <td>1.846673</td>\n",
       "      <td>4.139393</td>\n",
       "      <td>1.930237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <td>0.928480</td>\n",
       "      <td>2.231032</td>\n",
       "      <td>0.975955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <td>0.090145</td>\n",
       "      <td>0.239698</td>\n",
       "      <td>0.095596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <td>0.030688</td>\n",
       "      <td>0.184383</td>\n",
       "      <td>0.036290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <td>0.012728</td>\n",
       "      <td>0.156725</td>\n",
       "      <td>0.017977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <td>0.008718</td>\n",
       "      <td>0.152116</td>\n",
       "      <td>0.013945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_11</th>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_12</th>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0          1      total\n",
       "ps_car_03_cat  69.358067  61.998709  69.089837\n",
       "ps_car_05_cat  45.002772  38.960081  44.782531\n",
       "ps_reg_03      18.257840  14.105283  18.106490\n",
       "ps_car_14       7.130901   7.942288   7.160474\n",
       "ps_car_07_cat   1.846673   4.139393   1.930237\n",
       "ps_ind_05_cat   0.928480   2.231032   0.975955\n",
       "ps_car_09_cat   0.090145   0.239698   0.095596\n",
       "ps_ind_02_cat   0.030688   0.184383   0.036290\n",
       "ps_car_01_cat   0.012728   0.156725   0.017977\n",
       "ps_ind_04_cat   0.008718   0.152116   0.013945\n",
       "ps_car_02_cat   0.000872   0.000000   0.000840\n",
       "ps_car_11       0.000872   0.000000   0.000840\n",
       "ps_car_12       0.000174   0.000000   0.000168\n",
       "ps_car_15       0.000000   0.000000   0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many missing values are we looking at?\n",
    "# percentage by classes\n",
    "df_tmp = df_train[['target']+all_features].groupby('target')[all_features]\\\n",
    ".apply(lambda x: 100*np.sum(x == -1)/len(x)).T\n",
    "# percentage by all classes\n",
    "df_tmp2 = (df_train[all_features].apply(lambda x: x == -1).sum() / df_train.shape[0] * 100)\\\n",
    ".to_frame()\n",
    "df_tmp2.rename(columns={0: 'total'}, inplace=True)\n",
    "# merge!\n",
    "df_tmp = df_tmp.merge(df_tmp2, left_index=True, right_index=True)\n",
    "del df_tmp2\n",
    "df_tmp.sort_values(by='total', ascending=False, inplace=True)\n",
    "df_tmp.head(14)  # there are 13 features with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing values\n",
    "Before we dive deep into the model, we need to deal with the missing values first. The simpliest method is just to ignore all the samples that as **any** missing value in there. However, by doing so, we reduce the total sample size from ~ 600k to less than 100k. \n",
    "\n",
    "Therefore, we need a better way to impute the missing values. Jingfei's current methodolgy is to treat the missing value as a new category, for the cases of binary and categorical features. (How about continuous features?)\n",
    "\n",
    "Another possibility is to geuss the missing values intelligently. To start, we can fill the missing binary and categorical values with the most frequency entries, and fill the missing continuous with their medians.\n",
    "\n",
    "There are much more can be done with regard to data imputation: for example, to train regression models on the missing variable, from other varibles. However, we need to keep in mind how to carry the regression to test data or new data, with missing entries. \n",
    "\n",
    "We have to pay special attention to those features with many missing values, namely, `ps_car_03_cat`, `ps_cat_05_cat`, `ps_reg_03`, etc.\n",
    "\n",
    "### Metric\n",
    "\n",
    "When comparing different imputation methods, we need have a unified metric to evaluate their success. The simplest metric can be the testing error - same as how we evaluate different models, but in this case, the model should stay the same. The default choice will be xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace -1 with nan for easier handling\n",
    "df_train.replace({-1: np.float('NaN')}, inplace=True)\n",
    "\n",
    "# helper function to get the best and last training, valid gini coefficients\n",
    "def get_gini_stats(eval_results):\n",
    "    last_training, last_valid = [], []\n",
    "    best_training, best_valid = [], []\n",
    "    for x in eval_results:\n",
    "        last_training.append(x['train']['gini'][-1])\n",
    "        last_valid.append(x['valid']['gini'][-1])\n",
    "        best_training.append(max(x['train']['gini']))\n",
    "        best_valid.append(max(x['valid']['gini']))\n",
    "    return last_training, last_valid, best_training, best_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: mode and median\n",
    "In the simplest case, let's fill the missing binary / categorical values with their mode, and continoues variables with their median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can also be done with sklearn\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html\n",
    "fills = {}  # make the dict so that we can fill test data\n",
    "for c in df_train.columns[2:]:\n",
    "    if c.endswith(('bin', 'cat')):\n",
    "        fills[c] = df_train[c].mode()[0]\n",
    "    else: \n",
    "        fills[c] = df_train[c].median()\n",
    "df_train_impute_1 = df_train.fillna(fills)\n",
    "# df_test_impute_1 = df_test.fillna(fills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted training/test, and applied standard scaler.\n",
      "Total number of training samples: 565451\n"
     ]
    }
   ],
   "source": [
    "%run '../py/models_ccy.py'\n",
    "clf = my_xgb(df_train_impute_1[all_features], \n",
    "             df_train_impute_1['target'].astype(int, inplace=True))\n",
    "clf.input_scaling(ratio=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 5 fold CV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/python27/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.229256\tvalid-gini:0.21061\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.386398\tvalid-gini:0.275273\n",
      "[200]\ttrain-gini:0.453984\tvalid-gini:0.272871\n",
      "Stopping. Best iteration:\n",
      "[137]\ttrain-gini:0.412761\tvalid-gini:0.276752\n",
      "\n",
      "Fold 2 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.232125\tvalid-gini:0.202841\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.389445\tvalid-gini:0.266435\n",
      "[200]\ttrain-gini:0.461067\tvalid-gini:0.266343\n",
      "Stopping. Best iteration:\n",
      "[135]\ttrain-gini:0.415507\tvalid-gini:0.268337\n",
      "\n",
      "Fold 3 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.233745\tvalid-gini:0.206239\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.388273\tvalid-gini:0.26885\n",
      "[200]\ttrain-gini:0.458829\tvalid-gini:0.269057\n",
      "Stopping. Best iteration:\n",
      "[167]\ttrain-gini:0.436883\tvalid-gini:0.270661\n",
      "\n",
      "Fold 4 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.232603\tvalid-gini:0.203013\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.385016\tvalid-gini:0.274802\n",
      "[200]\ttrain-gini:0.45133\tvalid-gini:0.272329\n",
      "Stopping. Best iteration:\n",
      "[115]\ttrain-gini:0.395818\tvalid-gini:0.275446\n",
      "\n",
      "Fold 5 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.22991\tvalid-gini:0.215678\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.387474\tvalid-gini:0.28779\n",
      "[200]\ttrain-gini:0.463766\tvalid-gini:0.286562\n",
      "Stopping. Best iteration:\n",
      "[122]\ttrain-gini:0.405068\tvalid-gini:0.288455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clf.one_hot_encoding()\n",
    "models_impute_1, eval_results_impute_1 = clf.fit(one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2729496\n",
      "0.00683717446318\n"
     ]
    }
   ],
   "source": [
    "last_training, last_valid, best_training, best_valid = get_gini_stats(eval_results_impute_1)\n",
    "print(np.mean(last_valid))\n",
    "print(np.std(last_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: random imputation\n",
    "The idea here is that, for the missing values, we want to fill them with values drawn randomly from their underlying distribution. We will use the existing values to infer the underlying distribution. This can be easily done for binary and categorical features. (How to do this for continous feature?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get distributions for a categorical feature\n",
    "def fill_w_distribution(s):\n",
    "    '''\n",
    "    Input\n",
    "    =======\n",
    "    s: <pd series>\n",
    "        with NaN as missing values. Binary or categorical feature\n",
    "    Return\n",
    "    =======\n",
    "    filled_s: <pd series>\n",
    "        without NaNs\n",
    "    '''\n",
    "    import numpy as np\n",
    "    \n",
    "    Xs = s.value_counts().index.values\n",
    "    p  = s.value_counts().values\n",
    "    p  = 1.0 * p / p.sum()\n",
    "    num_to_fill = s.isnull().sum()\n",
    "    idx_to_fill = s[s.isnull()].index\n",
    "    fills = np.random.choice(Xs, size=num_to_fill, p=p)\n",
    "    val_to_fill = pd.Series(fills, index=idx_to_fill)\n",
    "    # fill it!\n",
    "    filled_s = s.add(val_to_fill, fill_value=0)\n",
    "    \n",
    "    return filled_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_impute_2 = df_train.copy()\n",
    "for c in df_train_impute_2.columns[2:]:\n",
    "    if c.endswith(('bin', 'cat')):\n",
    "        df_train_impute_2[c] = fill_w_distribution(df_train_impute_2[c])       \n",
    "# fill the continous NaN with median \n",
    "df_train_impute_2 = df_train_impute_2.fillna(df_train_impute_2.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted training/test, and applied standard scaler.\n",
      "Total number of training samples: 565451\n"
     ]
    }
   ],
   "source": [
    "clf = my_xgb(df_train_impute_2[all_features], \n",
    "             df_train_impute_2['target'].astype(int, inplace=True))\n",
    "clf.input_scaling(ratio=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 5 fold CV\n",
      "Fold 1 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.226659\tvalid-gini:0.199199\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.385047\tvalid-gini:0.270573\n",
      "[200]\ttrain-gini:0.459176\tvalid-gini:0.271141\n",
      "Stopping. Best iteration:\n",
      "[151]\ttrain-gini:0.424283\tvalid-gini:0.272074\n",
      "\n",
      "Fold 2 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.230289\tvalid-gini:0.203716\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.388984\tvalid-gini:0.275365\n",
      "[200]\ttrain-gini:0.459629\tvalid-gini:0.274149\n",
      "Stopping. Best iteration:\n",
      "[142]\ttrain-gini:0.420898\tvalid-gini:0.276718\n",
      "\n",
      "Fold 3 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.230899\tvalid-gini:0.200549\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.387897\tvalid-gini:0.27248\n",
      "[200]\ttrain-gini:0.458241\tvalid-gini:0.272083\n",
      "Stopping. Best iteration:\n",
      "[118]\ttrain-gini:0.403093\tvalid-gini:0.274182\n",
      "\n",
      "Fold 4 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.232528\tvalid-gini:0.206875\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.38761\tvalid-gini:0.269161\n",
      "[200]\ttrain-gini:0.456982\tvalid-gini:0.26811\n",
      "Stopping. Best iteration:\n",
      "[147]\ttrain-gini:0.423507\tvalid-gini:0.27094\n",
      "\n",
      "Fold 5 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.233414\tvalid-gini:0.206926\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.386456\tvalid-gini:0.271166\n",
      "[200]\ttrain-gini:0.459558\tvalid-gini:0.273034\n",
      "Stopping. Best iteration:\n",
      "[176]\ttrain-gini:0.443012\tvalid-gini:0.273579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clf.one_hot_encoding()\n",
    "models_impute_2, eval_results_impute_2 = clf.fit(one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2701592\n",
      "0.00268336008765\n"
     ]
    }
   ],
   "source": [
    "last_training, last_valid, best_training, best_valid = get_gini_stats(eval_results_impute_2)\n",
    "print(np.mean(last_valid))\n",
    "print(np.std(last_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: imputation with joint distribution\n",
    "The idea is that, we want to guess the missing values of one feature, with the joint distribution bewteen this feature and other features. In another word, we want to train a simple model to predict the missing values. A possible model can be Naive Bayes with Gaussian distribution. The choice of such model is that there is no hyper parameter, hence we can just keep things simple (to start with)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_wo_nan, feature_w_nan = [], []\n",
    "for c in df_train.iloc[:, 2:]:\n",
    "    if df_train[c].isnull().sum() == 0:\n",
    "        feature_wo_nan.append(c)\n",
    "    else:\n",
    "        feature_w_nan.append(c)\n",
    "\n",
    "def fill_w_NB(df_train, col, feature_wo_na):\n",
    "    '''\n",
    "    Input\n",
    "    =========\n",
    "    df_train: <pd dataframe>\n",
    "        dataframe with the NaN features\n",
    "    col: <str>\n",
    "        name of the column to fit\n",
    "    feature_wo_nan: <list>\n",
    "        list of column names without NaN features\n",
    "        \n",
    "    Return\n",
    "    =========\n",
    "    filled_s: <pd Series>\n",
    "        pandas series without NaN\n",
    "    gnb: <>\n",
    "    '''\n",
    "    \n",
    "    # get the 'training' and 'test' set\n",
    "    df_tmp = df_train.iloc[:, 2:]\n",
    "    df_train_tmp = df_tmp[df_tmp[col].notnull()]\n",
    "    df_test_tmp = df_tmp[df_tmp[col].isnull()]\n",
    "    df_test_tmp.drop(col, axis=1, inplace=True)\n",
    "    # train a NB model\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(df_train_tmp[feature_wo_nan], df_train_tmp[col])\n",
    "    fills = gnb.predict(df_test_tmp[feature_wo_nan])\n",
    "    val_to_fill = pd.Series(fills, index=df_test_tmp.index)\n",
    "    filled_s = df_tmp[col].add(val_to_fill, fill_value=0)\n",
    "    \n",
    "    return filled_s, gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/python27/lib/python2.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "impute_3_models = {}\n",
    "df_train_impute_3 = df_train.copy()\n",
    "for f in feature_w_nan:\n",
    "    if f.endswith(('cat', 'bin')):\n",
    "        filled_s, model = fill_w_NB(df_train, f, feature_wo_nan)\n",
    "        df_train_impute_3[f] = filled_s\n",
    "        impute_3_models[f] = model\n",
    "# fill continouse features with median\n",
    "df_train_impute_3 = df_train_impute_3.fillna(df_train_impute_3.median()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted training/test, and applied standard scaler.\n",
      "Total number of training samples: 565451\n"
     ]
    }
   ],
   "source": [
    "clf = my_xgb(df_train_impute_3[all_features], \n",
    "             df_train_impute_3['target'].astype(int, inplace=True))\n",
    "clf.input_scaling(ratio=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 5 fold CV\n",
      "Fold 1 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.232632\tvalid-gini:0.200026\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.38412\tvalid-gini:0.278988\n",
      "[200]\ttrain-gini:0.458704\tvalid-gini:0.279598\n",
      "Stopping. Best iteration:\n",
      "[169]\ttrain-gini:0.436914\tvalid-gini:0.281969\n",
      "\n",
      "Fold 2 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.233138\tvalid-gini:0.186181\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.3925\tvalid-gini:0.261193\n",
      "[200]\ttrain-gini:0.464098\tvalid-gini:0.25996\n",
      "Stopping. Best iteration:\n",
      "[151]\ttrain-gini:0.431637\tvalid-gini:0.262414\n",
      "\n",
      "Fold 3 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.225105\tvalid-gini:0.210068\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.387231\tvalid-gini:0.285052\n",
      "[200]\ttrain-gini:0.457432\tvalid-gini:0.283248\n",
      "Stopping. Best iteration:\n",
      "[101]\ttrain-gini:0.388183\tvalid-gini:0.285178\n",
      "\n",
      "Fold 4 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.229884\tvalid-gini:0.217775\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.387795\tvalid-gini:0.281638\n",
      "[200]\ttrain-gini:0.459385\tvalid-gini:0.279739\n",
      "Stopping. Best iteration:\n",
      "[108]\ttrain-gini:0.394134\tvalid-gini:0.282105\n",
      "\n",
      "Fold 5 of 5\n",
      "class weight is: 26\n",
      "[0]\ttrain-gini:0.233493\tvalid-gini:0.200995\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.389803\tvalid-gini:0.275289\n",
      "[200]\ttrain-gini:0.457461\tvalid-gini:0.275009\n",
      "Stopping. Best iteration:\n",
      "[164]\ttrain-gini:0.43483\tvalid-gini:0.276764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clf.one_hot_encoding()\n",
    "models_impute_3, eval_results_impute_3 = clf.fit(one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2737044\n",
      "0.00881330388901\n"
     ]
    }
   ],
   "source": [
    "last_training, last_valid, best_training, best_valid = get_gini_stats(eval_results_impute_3)\n",
    "print(np.mean(last_valid))\n",
    "print(np.std(last_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
