{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (595212, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin       ...        \\\n",
       "0              0              0              1              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "2              0              0              0              1       ...         \n",
       "3              0              1              0              0       ...         \n",
       "4              0              1              0              0       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the raw data\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "print('Shape of the dataset: {}'.format(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    573518\n",
       "1     21694\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is there class imbalance? The answer is very much..., it's 3.6%\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what features are we looking at?\n",
    "# there are 57 features in total (=59-2)\n",
    "all_features = df.columns.tolist()\n",
    "all_features.remove('target')\n",
    "all_features.remove('id')\n",
    "bin_features = []\n",
    "cat_features = []\n",
    "other_features = []\n",
    "for col in df.columns:\n",
    "    if col.split('_')[-1] == 'bin':\n",
    "        bin_features.append(col)\n",
    "    elif col.split('_')[-1] == 'cat':\n",
    "        cat_features.append(col)\n",
    "    else:\n",
    "        other_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bin_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ps_ind_01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_reg_01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_reg_02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_reg_03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_03_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_04_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_05_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_06_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_08_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_10_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_11_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_07</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_08</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target            0    1\n",
       "ps_ind_01       0.0  0.0\n",
       "ps_ind_02_cat   0.0  0.0\n",
       "ps_ind_03       0.0  0.0\n",
       "ps_ind_04_cat   0.0  0.0\n",
       "ps_ind_05_cat   0.0  0.0\n",
       "ps_ind_06_bin   0.0  0.0\n",
       "ps_ind_07_bin   0.0  0.0\n",
       "ps_ind_08_bin   0.0  0.0\n",
       "ps_ind_09_bin   0.0  0.0\n",
       "ps_ind_10_bin   0.0  0.0\n",
       "ps_ind_11_bin   0.0  0.0\n",
       "ps_ind_12_bin   0.0  0.0\n",
       "ps_ind_13_bin   0.0  0.0\n",
       "ps_ind_14       0.0  0.0\n",
       "ps_ind_15       0.0  0.0\n",
       "ps_ind_16_bin   0.0  0.0\n",
       "ps_ind_17_bin   0.0  0.0\n",
       "ps_ind_18_bin   0.0  0.0\n",
       "ps_reg_01       0.0  0.0\n",
       "ps_reg_02       0.0  0.0\n",
       "ps_reg_03       0.0  0.0\n",
       "ps_car_01_cat   0.0  0.0\n",
       "ps_car_02_cat   0.0  0.0\n",
       "ps_car_03_cat   0.0  0.0\n",
       "ps_car_04_cat   0.0  0.0\n",
       "ps_car_05_cat   0.0  0.0\n",
       "ps_car_06_cat   0.0  0.0\n",
       "ps_car_07_cat   0.0  0.0\n",
       "ps_car_08_cat   0.0  0.0\n",
       "ps_car_09_cat   0.0  0.0\n",
       "ps_car_10_cat   0.0  0.0\n",
       "ps_car_11_cat   0.0  0.0\n",
       "ps_car_11       0.0  0.0\n",
       "ps_car_12       0.0  0.0\n",
       "ps_car_13       0.0  0.0\n",
       "ps_car_14       0.0  0.0\n",
       "ps_car_15       0.0  0.0\n",
       "ps_calc_01      0.0  0.0\n",
       "ps_calc_02      0.0  0.0\n",
       "ps_calc_03      0.0  0.0\n",
       "ps_calc_04      0.0  0.0\n",
       "ps_calc_05      0.0  0.0\n",
       "ps_calc_06      0.0  0.0\n",
       "ps_calc_07      0.0  0.0\n",
       "ps_calc_08      0.0  0.0\n",
       "ps_calc_09      0.0  0.0\n",
       "ps_calc_10      0.0  0.0\n",
       "ps_calc_11      0.0  0.0\n",
       "ps_calc_12      0.0  0.0\n",
       "ps_calc_13      0.0  0.0\n",
       "ps_calc_14      0.0  0.0\n",
       "ps_calc_15_bin  0.0  0.0\n",
       "ps_calc_16_bin  0.0  0.0\n",
       "ps_calc_17_bin  0.0  0.0\n",
       "ps_calc_18_bin  0.0  0.0\n",
       "ps_calc_19_bin  0.0  0.0\n",
       "ps_calc_20_bin  0.0  0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many missing values, in terms of percentage, are we looking at?\n",
    "df[['target']+all_features].groupby('target')[all_features]\\\n",
    ".apply(lambda x: 100*np.sum(x == -1)/len(x)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace the -1 with NaN, so that I can use pandas.dropna...\n",
    "df.replace({-1: np.float('NaN')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    573518\n",
      "1     21694\n",
      "Name: target, dtype: int64\n",
      "0    119261\n",
      "1      5670\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# how to deal with those missing (-1) values? \n",
    "# what if I just drop them?\n",
    "print(df['target'].value_counts())  # classes before dropna\n",
    "df.dropna(how='any', inplace=True)\n",
    "print(df['target'].value_counts())  # classes after dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04538505254900705"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5670 / (5670+119261)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's handle everything in a class\n",
    "class Classifier():\n",
    "    '''\n",
    "    In this class, we will do everything, including:\n",
    "    (1) data cleaning, imputation, scaling\n",
    "    (2) possible feature engineering\n",
    "    (3) model fitting, including CV \n",
    "    (4) prediction on test data\n",
    "    (5) helper functions such as various plotting functions\n",
    "    \n",
    "    Here we heavily rely on the pandas, hence most of the datatypes is pandas dataframe\n",
    "    '''\n",
    "    def __init__(self, X_raw, y_raw):\n",
    "        '''\n",
    "        Initialization.\n",
    "        Here we assume there is no missing entry (with value of -1)\n",
    "        in the data, i.e., we've done the data cleaning step.\n",
    "        \n",
    "        Input\n",
    "        =====================\n",
    "        X_raw: <pandas dataframe> \n",
    "            The raw input, in pandas dataframe. \n",
    "            The shape should be m x n,\n",
    "            where m is the number of sample, n is the number of features\n",
    "        Y_raw: <pandas dataframe>\n",
    "            The raw binary labels, in pandas dataframe.\n",
    "            The shape should be m x 1\n",
    "            \n",
    "        Return\n",
    "        =====================\n",
    "        Nothing\n",
    "        '''\n",
    "        import time\n",
    "        \n",
    "        self.X_raw = X_raw\n",
    "        self.y_raw = y_raw\n",
    "        # check for missing values\n",
    "        tmp_cnt = 0\n",
    "        tmp_cols = []\n",
    "        for col in X_raw.columns:\n",
    "            if X_raw[col].min() < 0:\n",
    "                tmp_cnt += 1\n",
    "                tmp_cols.append(col)\n",
    "        if tmp_cnt > 0:\n",
    "            print('Thre are {} features with missing value(s)'.format(tmp_cnt))\n",
    "            print('They are:')\n",
    "            for x in tmp_cols:\n",
    "                print('    ', x)\n",
    "            print('======= Please deal with the missing values first! =======\\n')\n",
    "    \n",
    "    def plot_roc(self, fpr, tpr, roc_auc, model_type='not specified'):\n",
    "        \"\"\"\n",
    "        Helper function. \n",
    "        To plot the ROC curve for a binary classifier.\n",
    "        \n",
    "        Input:\n",
    "        =========\n",
    "        fpr: <float>\n",
    "            false positive rate\n",
    "        tpr: <float>\n",
    "            true positive rate\n",
    "        roc_auc: <???>\n",
    "            ???\n",
    "            \n",
    "        Return:\n",
    "        =========\n",
    "        Nothing, draw a plot.\n",
    "        \"\"\"        \n",
    "        \n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color='darkorange',\n",
    "                 lw=lw, label='ROC curve (area = {:0.6f})'.format(roc_auc))\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic for {}'.format(model_type))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    def get_gini(self):\n",
    "        '''\n",
    "        TODO: calculate the gini coefficent\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def get_importance(self, clf, X, N=3):\n",
    "        \"\"\"\n",
    "        For the Random Forest and XGB, to get the feature importance\n",
    "        \n",
    "        TODO: finish the doc\n",
    "        \"\"\"\n",
    "        features = X.columns\n",
    "        importances = [[c, i] for c, i in zip(features, clf.feature_importances_)];\n",
    "        importances = sorted(importances, key=lambda x: x[1], reverse = True);\n",
    "        N = 3\n",
    "        print('\\nThe top {} important features are:'.format(N))\n",
    "        for j in range(N):\n",
    "            print(importances[j][0], importances[j][1])     \n",
    "    \n",
    "    def input_scaling(self, ratio=0.2):\n",
    "        '''\n",
    "        First split the total data into training and testing, with given ratio\n",
    "        and the apply the standard scaler to the training data\n",
    "        \n",
    "        Input\n",
    "        ================\n",
    "        ratio: <float>, default: 0.2\n",
    "            ratio between test and training data sizes\n",
    "        \n",
    "        Return\n",
    "        ================\n",
    "        X_train: <pandas dataframe> \n",
    "            scaled training X\n",
    "        y_train: <pandas dataframe>\n",
    "            labels for the training X\n",
    "        X_test: <pandas dataframe>\n",
    "            scaled test X\n",
    "        y_test: <pandas dataframe>\n",
    "            lables for test X\n",
    "        '''\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        #from sklearn.model_selection import GridSearchCV\n",
    "        #from sklearn.metrics import confusion_matrix\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test \\\n",
    "            = train_test_split(self.X_raw, self.y_raw, test_size=ratio)\n",
    "        # scaling the features\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(self.X_train)  # Don't cheat - fit only on training data\n",
    "        \n",
    "        self.X_train = scaler.transform(self.X_train)\n",
    "        self.X_test = scaler.transform(self.X_test)  # apply same transformation to test data\n",
    "        print('Splitted training/test, and applied standard scaler.')\n",
    "        print('Total number of training samples: {}'.format(len(self.X_train)))\n",
    "        \n",
    "    def logistic_regression(self, tuning=True, roc_plot=True):\n",
    "        '''\n",
    "        Build a logistic regression model.\n",
    "        \n",
    "        Input:\n",
    "        ======\n",
    "        tuning: <Boolean> default: True\n",
    "            If True, perform the hyper parameter tuning, with GridSearch CV\n",
    "        roc_plot: <Boolean> default: True\n",
    "            If True, plot the roc plot and calculate AUC\n",
    "        \n",
    "        Return:\n",
    "        =======\n",
    "        Nothing, but build a logistic regression classifier.\n",
    "        '''\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        \n",
    "        print('......Training a logistic regression model......')\n",
    "        # get the single classifier\n",
    "        self.lg_clf = LogisticRegression(class_weight='balanced')\n",
    "        # hyper parameters\n",
    "        parameters = {'C': np.logspace(-3, 0, num=30)}\n",
    "        \n",
    "        if tuning:  # hyper parameter tuning\n",
    "            lg_clfs = GridSearchCV(self.lg_clf, parameters, \n",
    "                                   verbose = 1, cv = 5, n_jobs = -1)\n",
    "            lg_clfs.fit(self.X_train, self.y_train)\n",
    "            self.lg_clf = lg_clfs.best_estimator_\n",
    "        else:\n",
    "            self.lg_clf.fit(self.X_train, self.y_train)\n",
    "        print('The training score is: {}'.format(self.lg_clf.score(self.X_train, self.y_train)))\n",
    "        print('The test score is: {}'.format(self.lg_clf.score(self.X_test, self.y_test)))\n",
    "        \n",
    "        if roc_plot:\n",
    "            ## get the roc curve\n",
    "            y_score = self.lg_clf.decision_function(self.X_test)\n",
    "            fpr, tpr, _ = roc_curve(self.y_test, y_score, drop_intermediate=False)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            self.plot_roc(fpr, tpr, roc_auc, model_type='Logistic Regression')\n",
    "            \n",
    "    def random_forest(self, tuning=True, roc_plot=True):\n",
    "        '''\n",
    "        Build a random forest model.\n",
    "        \n",
    "        Input:\n",
    "        ======\n",
    "        tuning: <Boolean> default: True\n",
    "            If True, perform the hyper parameter tuning, with GridSearch CV\n",
    "        roc_plot: <Boolean> default: True\n",
    "            If True, plot the roc plot and calculate AUC\n",
    "        \n",
    "        Return:\n",
    "        =======\n",
    "        Nothing, but build a random forest classifier.\n",
    "        '''\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        \n",
    "        print('......Training a random forest model......')\n",
    "        parameters = {'max_depth': [x for x in range(3, 21, 1)],\n",
    "              'n_estimators':[x for x in range(100, 401, 100)]}\n",
    "        self.rf_clf = RandomForestClassifier(class_weight='balanced',\n",
    "                                             verbose = False, random_state = True)\n",
    "        if tuning:\n",
    "            rf_clfs = GridSearchCV(self.rf_clf, parameters, \n",
    "                                   verbose = 1, cv = 5, n_jobs = -1)\n",
    "            rf_clfs.fit(self.X_train, self.y_train)\n",
    "            self.rf_clf = rf_clfs.best_estimator_\n",
    "        else:\n",
    "            self.rf_clf.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        print('The training score is: {}'.format(self.rf_clf.score(self.X_train, self.y_train)))\n",
    "        print('The test score is: {}'.format(self.rf_clf.score(self.X_test, self.y_test)))\n",
    "        \n",
    "        if roc_plot:\n",
    "            ## get the roc curve\n",
    "            y_score = self.rf_clf.predict_proba(self.X_test)\n",
    "            y_score = [x[1] for x in y_score]\n",
    "            fpr, tpr, _ = roc_curve(self.y_test, y_score, drop_intermediate=False)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            self.plot_roc(fpr, tpr, roc_auc, model_type='Random Forest')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted training/test, and applied standard scaler.\n",
      "Total number of training samples: 99944\n",
      "Training a logistic regression model...\n",
      "The training score is: 0.6098415112462979\n",
      "The test score is: 0.60747588746148\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTxTOOeei8kThnHMuqv8DNaGheOqi0SgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b9af550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_raw, y_raw = df[all_features], df['target']\n",
    "clf = Classifier(X_raw=X_raw, y_raw=y_raw)\n",
    "clf.input_scaling()\n",
    "# get the logistic regression going\n",
    "clf.logistic_regression(tuning=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a random forest model...\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.9min\n"
     ]
    }
   ],
   "source": [
    "clf.random_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
